{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: THEANO_FLAGS=device=cpu,floatX=float64\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from collections import OrderedDict\n",
    "from copy import deepcopy\n",
    "from time import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.special as sc\n",
    "\n",
    "import pymc3 as pm\n",
    "import seaborn as sns\n",
    "import theano\n",
    "import theano.tensor as tt\n",
    "\n",
    "from pymc3 import Dirichlet, Poisson, Gamma, Normal, Bernoulli\n",
    "from pymc3 import math as pmmath\n",
    "# from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from theano import shared\n",
    "from theano.sandbox.rng_mrg import MRG_RandomStreams\n",
    "\n",
    "%env THEANO_FLAGS=device=cpu,floatX=float64\n",
    "\n",
    "\n",
    "from data_prep import prepare_sparse_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_words = 3000\n",
    "n_samples = 10000\n",
    "\n",
    "tf_vectorizer, docs_tr = prepare_sparse_matrix(n_samples, n_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = tf_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "808287"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_tokens = np.sum(docs_tr[docs_tr.nonzero()])\n",
    "n_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logp_prob(beta, theta, h):\n",
    "    \"\"\"Returns the log-likelihood function for given documents.\n",
    "\n",
    "    K : number of topics in the model\n",
    "    V : number of words (size of vocabulary)\n",
    "    D : number of documents (in a mini-batch)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    beta : tensor (K x V)\n",
    "        Word distributions.\n",
    "    theta : tensor (D x K)\n",
    "        Topic distributions for documents.\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "    \\log p(d | theta, beta) = \\sum_w \\log p(w | theta, beta)\n",
    "                            = \\sum_w \\log Poisson(w | theta @ beta) \n",
    "                            = \\sum_w \\log Poisson(w | \\sum_k theta_k * beta_k)\n",
    "                            = \\sum_w \\log Poisson(w | \\sum_k \\exp( \\log theta_k + \\log beta_k ))\n",
    "                            = \\sum_w - \\sum_k \\exp( \\log theta_k + \\log beta_k ) + w * \\log \\sum_k \\exp( \\log theta_k + \\log beta_k ) - \\log gamma(w + 1)\n",
    "    \"\"\"\n",
    "\n",
    "    def ll_docs_f(docs):\n",
    "        dixs, vixs = docs.nonzero()\n",
    "        vfreqs = docs[dixs, vixs]\n",
    "\n",
    "        ll_docs = (\n",
    "            ((theta * h)[dixs] + beta.T[vixs]).sum(1) + \n",
    "            vfreqs * pmmath.logsumexp(tt.log((theta * h)[dixs]) + tt.log(beta.T[vixs]), axis=1).ravel() - \\\n",
    "            pm.distributions.special.gammaln(vfreqs + 1)\n",
    "        )\n",
    "        # Per-word log-likelihood times num of tokens in the whole dataset\n",
    "        return tt.sum(ll_docs) / (tt.sum(vfreqs) + 1e-9) * n_tokens\n",
    "\n",
    "    return ll_docs_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/liutianc/miniconda3/lib/python3.7/site-packages/pymc3/data.py:246: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  self.shared = theano.shared(data[in_memory_slc])\n",
      "/home/liutianc/miniconda3/lib/python3.7/site-packages/theano/tensor/subtensor.py:2197: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  rval = inputs[0].__getitem__(inputs[1:])\n",
      "/home/liutianc/miniconda3/lib/python3.7/site-packages/theano/tensor/subtensor.py:2197: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  rval = inputs[0].__getitem__(inputs[1:])\n",
      "/home/liutianc/miniconda3/lib/python3.7/site-packages/theano/tensor/subtensor.py:2197: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  rval = inputs[0].__getitem__(inputs[1:])\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "CompoundStep\n",
      ">Metropolis: [h]\n",
      ">Metropolis: [h0]\n",
      ">Metropolis: [w]\n",
      ">Metropolis: [theta]\n",
      ">Metropolis: [gamma]\n",
      ">Metropolis: [gamma0]\n",
      ">Metropolis: [beta]\n",
      "INFO (theano.gof.compilelock): Waiting for existing lock by process '3751047' (I am process '3760460')\n",
      "INFO (theano.gof.compilelock): To manually release the lock, delete /home/liutianc/.theano/compiledir_Linux-5.4--generic-x86_64-with-debian-bullseye-sid-x86_64-3.7.7-64/lock_dir\n",
      "INFO (theano.gof.compilelock): Waiting for existing lock by process '3751047' (I am process '3760460')\n",
      "INFO (theano.gof.compilelock): To manually release the lock, delete /home/liutianc/.theano/compiledir_Linux-5.4--generic-x86_64-with-debian-bullseye-sid-x86_64-3.7.7-64/lock_dir\n",
      "INFO (theano.gof.compilelock): Waiting for existing lock by process '3751047' (I am process '3760460')\n",
      "INFO (theano.gof.compilelock): To manually release the lock, delete /home/liutianc/.theano/compiledir_Linux-5.4--generic-x86_64-with-debian-bullseye-sid-x86_64-3.7.7-64/lock_dir\n",
      "INFO (theano.gof.compilelock): Waiting for existing lock by process '3751047' (I am process '3760460')\n",
      "INFO (theano.gof.compilelock): To manually release the lock, delete /home/liutianc/.theano/compiledir_Linux-5.4--generic-x86_64-with-debian-bullseye-sid-x86_64-3.7.7-64/lock_dir\n",
      "INFO (theano.gof.compilelock): Waiting for existing lock by process '3751047' (I am process '3760460')\n",
      "INFO (theano.gof.compilelock): To manually release the lock, delete /home/liutianc/.theano/compiledir_Linux-5.4--generic-x86_64-with-debian-bullseye-sid-x86_64-3.7.7-64/lock_dir\n",
      "INFO (theano.gof.compilelock): Waiting for existing lock by process '3751047' (I am process '3760460')\n",
      "INFO (theano.gof.compilelock): To manually release the lock, delete /home/liutianc/.theano/compiledir_Linux-5.4--generic-x86_64-with-debian-bullseye-sid-x86_64-3.7.7-64/lock_dir\n",
      "INFO (theano.gof.compilelock): Waiting for existing lock by process '3751047' (I am process '3760460')\n",
      "INFO (theano.gof.compilelock): To manually release the lock, delete /home/liutianc/.theano/compiledir_Linux-5.4--generic-x86_64-with-debian-bullseye-sid-x86_64-3.7.7-64/lock_dir\n",
      "INFO (theano.gof.compilelock): Waiting for existing lock by process '3751047' (I am process '3760460')\n",
      "INFO (theano.gof.compilelock): To manually release the lock, delete /home/liutianc/.theano/compiledir_Linux-5.4--generic-x86_64-with-debian-bullseye-sid-x86_64-3.7.7-64/lock_dir\n",
      "INFO (theano.gof.compilelock): Waiting for existing lock by process '3751047' (I am process '3760460')\n",
      "INFO (theano.gof.compilelock): To manually release the lock, delete /home/liutianc/.theano/compiledir_Linux-5.4--generic-x86_64-with-debian-bullseye-sid-x86_64-3.7.7-64/lock_dir\n",
      "INFO (theano.gof.compilelock): Waiting for existing lock by process '3751047' (I am process '3760460')\n",
      "INFO (theano.gof.compilelock): To manually release the lock, delete /home/liutianc/.theano/compiledir_Linux-5.4--generic-x86_64-with-debian-bullseye-sid-x86_64-3.7.7-64/lock_dir\n",
      "INFO (theano.gof.compilelock): Waiting for existing lock by process '3751047' (I am process '3760460')\n",
      "INFO (theano.gof.compilelock): To manually release the lock, delete /home/liutianc/.theano/compiledir_Linux-5.4--generic-x86_64-with-debian-bullseye-sid-x86_64-3.7.7-64/lock_dir\n",
      "INFO (theano.gof.compilelock): Waiting for existing lock by process '3751047' (I am process '3760460')\n",
      "INFO (theano.gof.compilelock): To manually release the lock, delete /home/liutianc/.theano/compiledir_Linux-5.4--generic-x86_64-with-debian-bullseye-sid-x86_64-3.7.7-64/lock_dir\n",
      "INFO (theano.gof.compilelock): Waiting for existing lock by process '3751047' (I am process '3760460')\n",
      "INFO (theano.gof.compilelock): To manually release the lock, delete /home/liutianc/.theano/compiledir_Linux-5.4--generic-x86_64-with-debian-bullseye-sid-x86_64-3.7.7-64/lock_dir\n",
      "Sampling 4 chains, 0 divergences:   0%|          | 0/6000 [00:00<?, ?draws/s]/home/liutianc/miniconda3/lib/python3.7/site-packages/theano/tensor/subtensor.py:2197: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  rval = inputs[0].__getitem__(inputs[1:])\n",
      "/home/liutianc/miniconda3/lib/python3.7/site-packages/theano/tensor/subtensor.py:2197: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  rval = inputs[0].__getitem__(inputs[1:])\n",
      "/home/liutianc/miniconda3/lib/python3.7/site-packages/theano/tensor/subtensor.py:2197: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  rval = inputs[0].__getitem__(inputs[1:])\n",
      "/home/liutianc/miniconda3/lib/python3.7/site-packages/theano/tensor/subtensor.py:2197: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  rval = inputs[0].__getitem__(inputs[1:])\n",
      "Sampling 4 chains, 0 divergences: 100%|██████████| 6000/6000 [06:17<00:00, 15.89draws/s]\n",
      "INFO (theano.gof.compilelock): Waiting for existing lock by process '3749906' (I am process '3760460')\n",
      "INFO (theano.gof.compilelock): To manually release the lock, delete /home/liutianc/.theano/compiledir_Linux-5.4--generic-x86_64-with-debian-bullseye-sid-x86_64-3.7.7-64/lock_dir\n",
      "/home/liutianc/miniconda3/lib/python3.7/site-packages/theano/tensor/subtensor.py:2197: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  rval = inputs[0].__getitem__(inputs[1:])\n"
     ]
    }
   ],
   "source": [
    "n_topics = 20\n",
    "n_subtopics = n_topics // 2\n",
    "minibatch_size = 128\n",
    "\n",
    "avg_len = docs_tr.sum(1).mean()\n",
    "\n",
    "doc_t_minibatch = pm.Minibatch(docs_tr.toarray(), minibatch_size)\n",
    "doc_t = shared(docs_tr.toarray()[:minibatch_size])\n",
    "\n",
    "e0 = c0 = 1.\n",
    "f0 = .01\n",
    "pn = .5\n",
    "\n",
    "with pm.Model() as model:\n",
    "    beta = Dirichlet(\n",
    "        \"beta\",\n",
    "        a=pm.floatX((1.0 / n_topics) * np.ones((n_topics, n_words))),\n",
    "        shape=(n_topics, n_words),\n",
    "    )\n",
    "\n",
    "    gamma0 = Gamma(\n",
    "        \"gamma0\", \n",
    "        alpha=pm.floatX(e0 * np.ones((1, n_topics))),\n",
    "        beta=pm.floatX(f0 * np.ones((1, n_topics))),\n",
    "        shape=(minibatch_size, n_topics)\n",
    "    )\n",
    "    \n",
    "    gamma = Gamma(\n",
    "        \"gamma\",\n",
    "        alpha=gamma0, \n",
    "        beta=1 / 0.001,\n",
    "        shape=(minibatch_size, n_topics)\n",
    "    )\n",
    "\n",
    "    theta = Gamma(\n",
    "        \"theta\",\n",
    "        alpha=gamma,\n",
    "        beta=pm.floatX((pn / (1. - pn)) * np.ones((minibatch_size, n_topics))),\n",
    "        shape=(minibatch_size, n_topics),\n",
    "        total_size=n_samples,\n",
    "    )\n",
    "    \n",
    "    w = Normal(\n",
    "        'w',\n",
    "        mu=0.,\n",
    "        sigma=pm.floatX(10. * np.ones((minibatch_size, n_subtopics))),\n",
    "        shape=(minibatch_size, n_subtopics)\n",
    "    )\n",
    "    \n",
    "    h0 = Bernoulli(\n",
    "        'h0',\n",
    "        p=0.5,\n",
    "        shape=(n_subtopics, n_topics),\n",
    "    )\n",
    "    \n",
    "    h = Bernoulli(\n",
    "        'h',\n",
    "        logit_p=w @ h0,\n",
    "        shape=(minibatch_size, n_topics)\n",
    "    )\n",
    "    \n",
    "    # Note, that we defined likelihood with scaling, so here we need no additional `total_size` kwarg\n",
    "    doc = pm.DensityDist(\"doc\", logp_prob(beta, theta, h), observed=doc_t)\n",
    "\n",
    "    step = pm.Metropolis()\n",
    "    trace = pm.sample(1000, step)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Top words in each topic basd on the posterior mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_top_words(beta, feature_names, n_top_words=10):\n",
    "    for i in range(len(beta)):\n",
    "        print(\n",
    "            (\"Topic #%d: \" % i)\n",
    "            + \" , \".join([feature_names[j] for j in beta[i].argsort()[: -n_top_words - 1 : -1]])\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/liutianc/miniconda3/lib/python3.7/site-packages/pymc3/sampling.py:1247: UserWarning: samples parameter is smaller than nchains times ndraws, some draws and/or chains may not be represented in the returned posterior predictive sample\n",
      "  \"samples parameter is smaller than nchains times ndraws, some draws \"\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 1045.20it/s]\n"
     ]
    }
   ],
   "source": [
    "with model:\n",
    "    ppc = pm.sample_posterior_predictive(\n",
    "        trace, var_names=[\"theta\", \"beta\"], samples=1000, random_seed=1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 3000)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_dist = ppc['beta']\n",
    "topic_dist_mean = topic_dist.mean(0)\n",
    "topic_dist_mean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #0: abandoned , abilities , ability , able , absolute , absolutely , abuse , abysmal , accent , acceptable\n",
      "Topic #1: abandoned , abilities , ability , able , absolute , absolutely , abuse , abysmal , accent , acceptable\n",
      "Topic #2: abandoned , abilities , ability , able , absolute , absolutely , abuse , abysmal , accent , acceptable\n",
      "Topic #3: abandoned , abilities , ability , able , absolute , absolutely , abuse , abysmal , accent , acceptable\n",
      "Topic #4: abandoned , abilities , ability , able , absolute , absolutely , abuse , abysmal , accent , acceptable\n",
      "Topic #5: abandoned , abilities , ability , able , absolute , absolutely , abuse , abysmal , accent , acceptable\n",
      "Topic #6: abandoned , abilities , ability , able , absolute , absolutely , abuse , abysmal , accent , acceptable\n",
      "Topic #7: abandoned , abilities , ability , able , absolute , absolutely , abuse , abysmal , accent , acceptable\n",
      "Topic #8: abandoned , abilities , ability , able , absolute , absolutely , abuse , abysmal , accent , acceptable\n",
      "Topic #9: abandoned , abilities , ability , able , absolute , absolutely , abuse , abysmal , accent , acceptable\n",
      "Topic #10: abandoned , abilities , ability , able , absolute , absolutely , abuse , abysmal , accent , acceptable\n",
      "Topic #11: abandoned , abilities , ability , able , absolute , absolutely , abuse , abysmal , accent , acceptable\n",
      "Topic #12: abandoned , abilities , ability , able , absolute , absolutely , abuse , abysmal , accent , acceptable\n",
      "Topic #13: abandoned , abilities , ability , able , absolute , absolutely , abuse , abysmal , accent , acceptable\n",
      "Topic #14: abandoned , abilities , ability , able , absolute , absolutely , abuse , abysmal , accent , acceptable\n",
      "Topic #15: abandoned , abilities , ability , able , absolute , absolutely , abuse , abysmal , accent , acceptable\n",
      "Topic #16: abandoned , abilities , ability , able , absolute , absolutely , abuse , abysmal , accent , acceptable\n",
      "Topic #17: abandoned , abilities , ability , able , absolute , absolutely , abuse , abysmal , accent , acceptable\n",
      "Topic #18: abandoned , abilities , ability , able , absolute , absolutely , abuse , abysmal , accent , acceptable\n",
      "Topic #19: abandoned , abilities , ability , able , absolute , absolutely , abuse , abysmal , accent , acceptable\n"
     ]
    }
   ],
   "source": [
    "print_top_words(topic_dist_mean, feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'n'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/pymc3/model.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1000\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1001\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_vars\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_for\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1002\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'n'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-9158d20e9841>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     priorpc = pm.sample_prior_predictive(\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0mvar_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"n\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"beta\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"theta\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     )\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/pymc3/sampling.py\u001b[0m in \u001b[0;36msample_prior_predictive\u001b[0;34m(samples, model, vars, var_names, random_seed)\u001b[0m\n\u001b[1;32m   1493\u001b[0m     \u001b[0mnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_default_varnames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvars_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_transformed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1494\u001b[0m     \u001b[0;31m# draw_values fails with auto-transformed variables. transform them later!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1495\u001b[0;31m     \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdraw_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1496\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1497\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/pymc3/sampling.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1493\u001b[0m     \u001b[0mnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_default_varnames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvars_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_transformed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1494\u001b[0m     \u001b[0;31m# draw_values fails with auto-transformed variables. transform them later!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1495\u001b[0;31m     \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdraw_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1496\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1497\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/pymc3/model.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1001\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_vars\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_for\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1002\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1003\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1004\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1005\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmakefn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/pymc3/model.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    996\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    997\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 998\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_vars\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    999\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1000\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'n'"
     ]
    }
   ],
   "source": [
    "with model:\n",
    "    priorpc = pm.sample_prior_predictive(\n",
    "        var_names=[\"n\", \"beta\", \"theta\"], samples=50, random_seed=1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
