{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: THEANO_FLAGS=device=gpu,floatX=float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/liutianc/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/liutianc/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from collections import OrderedDict\n",
    "from copy import deepcopy\n",
    "from time import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.special as sc\n",
    "\n",
    "import pymc3 as pm\n",
    "import seaborn as sns\n",
    "import theano\n",
    "import theano.tensor as tt\n",
    "\n",
    "from pymc3 import Dirichlet, Poisson, Gamma\n",
    "from pymc3 import math as pmmath\n",
    "# from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from theano import shared\n",
    "from theano.sandbox.rng_mrg import MRG_RandomStreams\n",
    "\n",
    "%env THEANO_FLAGS=device=gpu,floatX=float64\n",
    "\n",
    "\n",
    "from data_prep import prepare_sparse_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_words = 3000\n",
    "n_samples = 10000\n",
    "\n",
    "tf_vectorizer, docs_tr, docs_te, labels_tr, labels_te = prepare_sparse_matrix(n_samples, n_samples // 10, n_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = tf_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "808487"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_tokens = np.sum(docs_tr[docs_tr.nonzero()])\n",
    "n_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_prob(beta, theta, n):\n",
    "    \"\"\"Returns the log-likelihood function for given documents.\n",
    "\n",
    "    K : number of topics in the model\n",
    "    V : number of words (size of vocabulary)\n",
    "    D : number of documents (in a mini-batch)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    beta : tensor (K x V)\n",
    "        Word distributions.\n",
    "    theta : tensor (D x K)\n",
    "        Topic distributions for documents.\n",
    "    n: tensor (D x 1)\n",
    "        Expected lengths of each documents\n",
    "    \"\"\"\n",
    "\n",
    "    def ll_docs_f(docs):\n",
    "        \n",
    "        \"\"\"\n",
    "        \\log p(d | theta, beta, n) = \\sum_w \\log p(w | theta, betaï¼Œ n)\n",
    "                                   = \\sum_w \\log Poisson(w | theta @ beta * n) \n",
    "                                   = \\sum_w \\log Poisson(w | n * \\sum_k theta_k * beta_k)\n",
    "                                   = \\sum_w \\log Poisson(w | n * \\sum_k \\exp( \\log theta_k + \\log beta_k ))\n",
    "                                   = \\sum_w - n * \\sum_k \\exp( \\log theta_k + \\log beta_k ) + w * \\log n * \\sum_k \\exp( \\log theta_k + \\log beta_k ) + const\n",
    "        \"\"\"\n",
    "        dixs, vixs = docs.nonzero()\n",
    "        vfreqs = docs[dixs, vixs]\n",
    "        ll_docs = (\n",
    "            vfreqs * (pmmath.logsumexp(tt.log(theta[dixs]) + tt.log(beta.T[vixs]), axis=1).ravel() + tt.log(n[dixs]).ravel()) \\\n",
    "             - tt.exp(pmmath.logsumexp(tt.log(theta[dixs]) + tt.log(beta.T[vixs],), axis=1)).ravel() * n[dixs].ravel() \\\n",
    "             - pm.distributions.special.gammaln(vfreqs + 1)\n",
    "\n",
    "        )\n",
    "        \n",
    "        # Per-word log-likelihood times num of tokens in the whole dataset\n",
    "        return tt.sum(ll_docs) / (tt.sum(vfreqs) + 1e-9) * n_tokens\n",
    "\n",
    "    return ll_docs_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/liutianc/miniconda3/lib/python3.7/site-packages/pymc3/data.py:246: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  self.shared = theano.shared(data[in_memory_slc])\n",
      "/home/liutianc/miniconda3/lib/python3.7/site-packages/theano/tensor/subtensor.py:2197: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  rval = inputs[0].__getitem__(inputs[1:])\n",
      "/home/liutianc/miniconda3/lib/python3.7/site-packages/theano/tensor/subtensor.py:2197: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  rval = inputs[0].__getitem__(inputs[1:])\n",
      "/home/liutianc/miniconda3/lib/python3.7/site-packages/theano/tensor/subtensor.py:2197: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  rval = inputs[0].__getitem__(inputs[1:])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "n_topics = 20\n",
    "minibatch_size = 128\n",
    "\n",
    "avg_len = docs_tr.sum(1).mean()\n",
    "\n",
    "doc_t_minibatch = pm.Minibatch(docs_tr.toarray(), minibatch_size)\n",
    "doc_t = shared(docs_tr.toarray()[:minibatch_size])\n",
    "\n",
    "with pm.Model() as model:\n",
    "    n = Gamma(\n",
    "        \"n\", \n",
    "        alpha=pm.floatX(10. * np.ones((minibatch_size, 1))),\n",
    "        beta=pm.floatX(1 / 10 * np.ones((minibatch_size, 1))),\n",
    "        shape=(minibatch_size, 1),\n",
    "        total_size=n_samples\n",
    "    )\n",
    "    \n",
    "    beta = Dirichlet(\n",
    "        \"beta\",\n",
    "        a=pm.floatX((1.0 / n_topics) * np.ones((n_topics, n_words))),\n",
    "        shape=(n_topics, n_words),\n",
    "    )\n",
    "\n",
    "    theta = Dirichlet(\n",
    "        \"theta\",\n",
    "        a=pm.floatX((1.0 / n_topics) * np.ones((minibatch_size, n_topics))),\n",
    "        shape=(minibatch_size, n_topics),\n",
    "        total_size=n_samples,\n",
    "    )\n",
    "    \n",
    "    doc = pm.DensityDist(\"doc\", log_prob(beta, theta, n), observed=doc_t)\n",
    "\n",
    "#     step = pm.Metropolis()\n",
    "#     trace = pm.sample(1000, step)\n",
    "    \n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VAE for n and \\theta variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LDAEncoder:\n",
    "    \"\"\"Encode (term-frequency) document vectors to variational means and (log-transformed) stds.\"\"\"\n",
    "\n",
    "    def __init__(self, n_words, n_hidden, n_topics, p_corruption=0, random_seed=1):\n",
    "        rng = np.random.RandomState(random_seed)\n",
    "        self.n_words = n_words\n",
    "        self.n_hidden = n_hidden\n",
    "        self.n_topics = n_topics\n",
    "        self.w0 = shared(0.01 * rng.randn(n_words, n_hidden).ravel(), name=\"w0\")\n",
    "        self.b0 = shared(0.01 * rng.randn(n_hidden), name=\"b0\")\n",
    "        \n",
    "        self.w1 = shared(0.01 * rng.randn(n_hidden, n_hidden).ravel(), name=\"w1\")\n",
    "        self.b1 = shared(0.01 * rng.randn(n_hidden), name=\"b1\")\n",
    "        \n",
    "        self.w2 = shared(0.01 * rng.randn(n_hidden, 2 * (n_topics - 1)).ravel(), name=\"w2\")\n",
    "        self.b2 = shared(0.01 * rng.randn(2 * (n_topics - 1)), name=\"b2\")\n",
    "        \n",
    "        self.w3 = shared(0.01 * rng.randn(n_hidden, 2).ravel(), name=\"w3\")\n",
    "        self.b3 = shared(0.01 * rng.randn(2), name=\"b3\")\n",
    "        \n",
    "        self.rng = MRG_RandomStreams(seed=random_seed)\n",
    "\n",
    "    def encode(self, xs):\n",
    "\n",
    "        w0 = self.w0.reshape((self.n_words, self.n_hidden))\n",
    "        w1 = self.w1.reshape((self.n_hidden, self.n_hidden))\n",
    "        w2 = self.w2.reshape((self.n_hidden, 2 * (self.n_topics - 1)))\n",
    "        w3 = self.w3.reshape((self.n_hidden, 2))\n",
    "\n",
    "        hs = tt.tanh(xs.dot(w0) + self.b0)\n",
    "        hs = tt.tanh(hs.dot(w1) + self.b1)\n",
    "        thetas = hs.dot(w2) + self.b2\n",
    "        rates = hs.dot(w3) + self.b3\n",
    "        \n",
    "        thetas_mean = thetas[:, :(self.n_topics - 1)]\n",
    "        thetas_rho = thetas[:, (self.n_topics - 1):]\n",
    "        \n",
    "        rates_mean = rates[:, :1]\n",
    "        rates_rho  = rates[:, 1:]\n",
    "        return {\"mu\": thetas_mean, \"rho\": thetas_rho}, {\"mu\": rates_mean, \"rho\": rates_rho}\n",
    "\n",
    "    def get_params(self):\n",
    "        return [self.w0, self.b0, self.w1, self.b1, self.w2, self.b2, self.w3, self.b3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[w0, b0, w1, b1, w2, b2, w3, b3]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = LDAEncoder(n_words=n_words, n_hidden=100, n_topics=n_topics, p_corruption=0.0)\n",
    "local_RVs = OrderedDict([(theta, encoder.encode(doc_t)[0]), (n, encoder.encode(doc_t)[1])])\n",
    "\n",
    "encoder_params = encoder.get_params()\n",
    "encoder_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([(theta,\n",
       "              {'mu': Subtensor{::, :int64:}.0,\n",
       "               'rho': Subtensor{::, int64::}.0}),\n",
       "             (n,\n",
       "              {'mu': Subtensor{::, :int64:}.0,\n",
       "               'rho': Subtensor{::, int64::}.0})])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local_RVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/200 [00:00<?, ?it/s]/home/liutianc/miniconda3/lib/python3.7/site-packages/theano/tensor/subtensor.py:2197: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  rval = inputs[0].__getitem__(inputs[1:])\n",
      "Average Loss = 1.2333e+14: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [00:53<00:00,  3.75it/s]\n",
      "Finished [100%]: Average Loss = 1.1778e+14\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pymc3.variational.approximations.MeanField at 0x7fe22192fe50>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = .1\n",
    "s = shared(lr)\n",
    "\n",
    "def reduce_rate(a, h, i):\n",
    "    s.set_value(lr / ((i / minibatch_size) + 1) ** 0.7)\n",
    "\n",
    "with model:\n",
    "    approx = pm.MeanField(local_rv=local_RVs)\n",
    "    approx.scale_cost_to_minibatch = False\n",
    "    inference = pm.KLqp(approx)\n",
    "    \n",
    "inference.fit(\n",
    "    200,\n",
    "    callbacks=[reduce_rate, pm.callbacks.CheckParametersConvergence(diff=\"absolute\")],\n",
    "#     callbacks=[pm.callbacks.CheckParametersConvergence(diff=\"absolute\")],\n",
    "    obj_optimizer=pm.adam(learning_rate=s),\n",
    "    more_obj_params=encoder_params,\n",
    "    total_grad_norm_constraint=200,\n",
    "    more_replacements={doc_t: doc_t_minibatch},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fe1a8036490>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(approx.hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #0: like ,really ,bad ,show ,story ,even ,would ,good ,time ,people\n",
      "Topic #1: career ,comedian ,add ,arms ,buddy ,books ,becoming ,answer ,ask ,bill\n",
      "Topic #2: appear ,appreciate ,clips ,begin ,breaking ,develop ,body ,bottom ,born ,bruce\n",
      "Topic #3: cole ,brief ,anime ,blood ,beloved ,act ,artistic ,country ,bank ,adult\n",
      "Topic #4: blockbuster ,bomb ,conversation ,adult ,concert ,cash ,account ,china ,covered ,cheap\n",
      "Topic #5: bound ,adult ,book ,achieved ,ashamed ,career ,alive ,change ,adding ,appreciated\n",
      "Topic #6: allow ,age ,burton ,bother ,cgi ,achieve ,accurate ,asked ,chemistry ,cost\n",
      "Topic #7: away ,agent ,box ,ages ,detailed ,considered ,appealing ,cares ,cause ,common\n",
      "Topic #8: alike ,cause ,brief ,colorful ,basement ,dozen ,asks ,combined ,bank ,boys\n",
      "Topic #9: chris ,believe ,average ,ability ,americans ,among ,adventure ,executed ,author ,eventually\n",
      "Topic #10: advice ,amazed ,arts ,ben ,african ,apart ,audience ,area ,clearly ,attractive\n",
      "Topic #11: accident ,ass ,apparently ,college ,amazing ,cartoons ,acts ,aware ,contrast ,country\n",
      "Topic #12: appears ,cassavetes ,angles ,balance ,angle ,amongst ,grant ,bored ,country ,building\n",
      "Topic #13: baseball ,asking ,birth ,christmas ,aside ,account ,amazingly ,background ,bright ,alive\n",
      "Topic #14: accident ,ago ,area ,doubt ,adult ,anyway ,creatures ,consequences ,blues ,able\n",
      "Topic #15: across ,african ,begins ,continue ,adventure ,ages ,authentic ,dig ,blues ,contains\n",
      "Topic #16: beach ,attack ,ability ,arthur ,arm ,actions ,career ,blown ,amusing ,cost\n",
      "Topic #17: ago ,bothered ,actress ,colorful ,afternoon ,absolutely ,alone ,anthony ,cheese ,christ\n",
      "Topic #18: admit ,bits ,adds ,amongst ,ali ,blind ,africa ,actress ,breath ,charge\n",
      "Topic #19: battle ,capture ,asian ,chris ,actor ,bomb ,anthony ,criminal ,brings ,adventures\n"
     ]
    }
   ],
   "source": [
    "def print_top_words(beta, feature_names, n_top_words=10):\n",
    "    for i in range(len(beta)):\n",
    "        print(\n",
    "            (\"Topic #%d: \" % i)\n",
    "            + \" ,\".join([feature_names[j] for j in beta[i].argsort()[: -n_top_words - 1 : -1]])\n",
    "        )\n",
    "\n",
    "doc_t.set_value(docs_tr.toarray())\n",
    "samples = pm.sample_approx(approx, draws=100)\n",
    "beta_pymc3 = samples[\"beta\"].mean(axis=0)\n",
    "\n",
    "print_top_words(beta_pymc3, feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 20, 3000)"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pm.sample_approx(approx, draws=100)['beta'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_pp(ws, thetas, beta, n, wix):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    ws: ndarray (N,)\n",
    "        Number of times the held-out word appeared in N documents.\n",
    "    thetas: ndarray, shape=(N, K)\n",
    "        Topic distributions for N documents.\n",
    "    beta: ndarray, shape=(K, V)\n",
    "        Word distributions for K topics.\n",
    "    wix: int\n",
    "        Index of the held-out word\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    Log probability of held-out words.\n",
    "    \"\"\"\n",
    "    rate = thetas.dot(beta[:, wix]) * n.ravel()\n",
    "    return ws * np.log(rate) - rate - sc.gammaln(ws + 1)\n",
    "\n",
    "\n",
    "def eval_dirpfa(transform, beta, docs_te, wixs):\n",
    "    \"\"\"Evaluate LDA model by log predictive probability.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    transform: Python function\n",
    "        Transform document vectors to posterior mean of topic proportions.\n",
    "    wixs: iterable of int\n",
    "        Word indices to be held-out.\n",
    "    \"\"\"\n",
    "    lpss = []\n",
    "    docs_ = deepcopy(docs_te)\n",
    "    thetass = []\n",
    "    wss = []\n",
    "    nss = []\n",
    "    total_words = 0\n",
    "    for wix in wixs:\n",
    "        ws = docs_te[:, wix].ravel()\n",
    "        if 0 < ws.sum():\n",
    "            # Hold-out\n",
    "            docs_[:, wix] = 0\n",
    "\n",
    "            # Topic distributions\n",
    "            thetas, ns = transform(docs_)\n",
    "\n",
    "            # Predictive log probability\n",
    "            lpss.append(calc_pp(ws, thetas, beta, ns, wix))\n",
    "\n",
    "            docs_[:, wix] = ws\n",
    "            thetass.append(thetas)\n",
    "            wss.append(ws)\n",
    "            nss.append(ns)\n",
    "            total_words += ws.sum()\n",
    "        else:\n",
    "            thetass.append(None)\n",
    "            wss.append(None)\n",
    "            nss.append(None)\n",
    "\n",
    "    # Log-probability\n",
    "    lp = np.sum(np.hstack(lpss)) / total_words\n",
    "\n",
    "    return {\"lp\": lp, \"lpss\": lpss, \"thetass\": thetass, \"beta\": beta, \"wss\": wss, \"nss\": nss}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/liutianc/miniconda3/lib/python3.7/site-packages/theano/scan_module/scan_perform_ext.py:76: UserWarning: The file scan_perform.c is not available. This donot happen normally. You are probably in a strangesetup. This mean Theano can not use the cython code for scan. If youwant to remove this warning, use the Theano flag'cxx=' (set to an empty string) to disable all ccode generation.\n",
      "  \"The file scan_perform.c is not available. This do\"\n",
      "/home/liutianc/miniconda3/lib/python3.7/site-packages/theano/scan_module/scan_perform_ext.py:76: UserWarning: The file scan_perform.c is not available. This donot happen normally. You are probably in a strangesetup. This mean Theano can not use the cython code for scan. If youwant to remove this warning, use the Theano flag'cxx=' (set to an empty string) to disable all ccode generation.\n",
      "  \"The file scan_perform.c is not available. This do\"\n"
     ]
    }
   ],
   "source": [
    "inp = tt.matrix(dtype=\"int64\")\n",
    "sample_vi_theta = theano.function(\n",
    "    [inp], approx.sample_node(approx.model.theta, 100, more_replacements={doc_t: inp}).mean(0)\n",
    ")\n",
    "\n",
    "sample_vi_n = theano.function(\n",
    "    [inp], approx.sample_node(approx.model.n, 100, more_replacements={doc_t: inp}).mean(0)\n",
    ")\n",
    "\n",
    "def transform_pymc3(docs):\n",
    "    return sample_vi_theta(docs), sample_vi_n(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = docs_te.toarray()\n",
    "\n",
    "theta_pymc3 = sample_vi_theta(test)\n",
    "n_pymc3 = sample_vi_n(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.00000000e+000, 2.22044605e-016, 4.93038066e-032, ...,\n",
       "        7.75325081e-267, 1.72156751e-282, 3.82264778e-298],\n",
       "       [1.00000000e+000, 2.22044605e-016, 4.93038066e-032, ...,\n",
       "        7.75325081e-267, 1.72156751e-282, 3.82264778e-298],\n",
       "       [1.00000000e+000, 2.22044605e-016, 4.93038066e-032, ...,\n",
       "        7.75325081e-267, 1.72156751e-282, 3.82264778e-298],\n",
       "       ...,\n",
       "       [1.00000000e+000, 2.22044605e-016, 4.93038066e-032, ...,\n",
       "        7.75325081e-267, 1.72156751e-282, 3.82264778e-298],\n",
       "       [1.00000000e+000, 2.22044605e-016, 4.93038066e-032, ...,\n",
       "        7.75325081e-267, 1.72156751e-282, 3.82264778e-298],\n",
       "       [1.00000000e+000, 2.22044605e-016, 4.93038066e-032, ...,\n",
       "        7.75325081e-267, 1.72156751e-282, 3.82264778e-298]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta_pymc3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/liutianc/miniconda3/lib/python3.7/site-packages/theano/scan_module/scan_perform_ext.py:76: UserWarning: The file scan_perform.c is not available. This donot happen normally. You are probably in a strangesetup. This mean Theano can not use the cython code for scan. If youwant to remove this warning, use the Theano flag'cxx=' (set to an empty string) to disable all ccode generation.\n",
      "  \"The file scan_perform.c is not available. This do\"\n",
      "/home/liutianc/miniconda3/lib/python3.7/site-packages/theano/scan_module/scan_perform_ext.py:76: UserWarning: The file scan_perform.c is not available. This donot happen normally. You are probably in a strangesetup. This mean Theano can not use the cython code for scan. If youwant to remove this warning, use the Theano flag'cxx=' (set to an empty string) to disable all ccode generation.\n",
      "  \"The file scan_perform.c is not available. This do\"\n"
     ]
    }
   ],
   "source": [
    "inp = tt.matrix(dtype=\"int64\")\n",
    "sample_vi_theta = theano.function(\n",
    "    [inp], approx.sample_node(approx.model.theta, 1000, more_replacements={doc_t: inp})\n",
    ")\n",
    "\n",
    "sample_vi_n = theano.function(\n",
    "    [inp], approx.sample_node(approx.model.n, 1000, more_replacements={doc_t: inp})\n",
    ")\n",
    "\n",
    "def transform_pymc3(docs):\n",
    "    return sample_vi_theta(docs), sample_vi_n(docs)\n",
    "\n",
    "pymc3_test = transform_pymc3(docs_te.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_low, theta_high = np.quantile(pymc3_test[0], [0.025, 0.975], axis=0)\n",
    "n_low, n_high = np.quantile(pymc3_test[1], [0.025, 0.975], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80.635"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_te.toarray().sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_cover = (n_low.ravel() < real_ln) & (n_high.ravel() > real_ln)\n",
    "is_cover.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = docs_te.toarray()\n",
    "real_ln = test.sum(1)\n",
    "# real_ln"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est_freq = ((theta_mean @ beta_pymc3) * n_mean).mean(0)\n",
    "# est_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rate = (theta_mean.dot(beta_pymc3) * pymc3_test[1].mean(0))\n",
    "rate.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp_test = (test * np.log(rate) - rate - sc.gammaln(test + 1)).sum(1) / real_ln"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(rate.sum(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(real_ln, rate.sum(1), 'o')\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
