{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: THEANO_FLAGS=device=cpu,floatX=float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/liutianc/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/liutianc/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from collections import OrderedDict\n",
    "from copy import deepcopy\n",
    "from time import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.special as sc\n",
    "\n",
    "import pymc3 as pm\n",
    "import seaborn as sns\n",
    "import theano\n",
    "import theano.tensor as tt\n",
    "\n",
    "from pymc3 import Dirichlet, Poisson, Gamma\n",
    "from pymc3 import math as pmmath\n",
    "# from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from theano import shared\n",
    "from theano.sandbox.rng_mrg import MRG_RandomStreams\n",
    "\n",
    "%env THEANO_FLAGS=device=cpu,floatX=float64\n",
    "\n",
    "\n",
    "from data_prep import prepare_sparse_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_words = 3000\n",
    "n_samples = 10000\n",
    "\n",
    "tf_vectorizer, docs_tr = prepare_sparse_matrix(n_samples, n_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = tf_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80.8287"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "808287"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_tokens = np.sum(docs_tr[docs_tr.nonzero()])\n",
    "n_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_prob(beta, theta):\n",
    "    \"\"\"Returns the log-likelihood function for given documents.\n",
    "\n",
    "    K : number of topics in the model\n",
    "    V : number of words (size of vocabulary)\n",
    "    D : number of documents (in a mini-batch)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    beta : tensor (K x V)\n",
    "        Word distributions.\n",
    "    theta : tensor (D x K)\n",
    "        Topic distributions for documents.\n",
    "    \"\"\"\n",
    "\n",
    "    def ll_docs_f(docs):\n",
    "        \n",
    "        dixs, vixs = docs.nonzero()\n",
    "        vfreqs = docs[dixs, vixs]\n",
    "        ll_docs = (\n",
    "            vfreqs * pmmath.logsumexp(tt.log(theta[dixs]) + tt.log(beta.T[vixs]), axis=1).ravel()\n",
    "        )\n",
    "\n",
    "        # Per-word log-likelihood times num of tokens in the whole dataset\n",
    "        return tt.sum(ll_docs) / (tt.sum(vfreqs) + 1e-9) * n_tokens\n",
    "\n",
    "    return ll_docs_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/liutianc/miniconda3/lib/python3.7/site-packages/pymc3/data.py:246: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  self.shared = theano.shared(data[in_memory_slc])\n",
      "/home/liutianc/miniconda3/lib/python3.7/site-packages/theano/tensor/subtensor.py:2197: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  rval = inputs[0].__getitem__(inputs[1:])\n"
     ]
    }
   ],
   "source": [
    "n_topics = 20\n",
    "minibatch_size = 128\n",
    "\n",
    "avg_len = docs_tr.sum(1).mean()\n",
    "\n",
    "doc_t_minibatch = pm.Minibatch(docs_tr.toarray(), minibatch_size)\n",
    "doc_t = shared(docs_tr.toarray()[:minibatch_size])\n",
    "\n",
    "\n",
    "e0 = c0 = 1.\n",
    "f0 = .01\n",
    "pn = .5\n",
    "\n",
    "with pm.Model() as model:\n",
    "    theta = Dirichlet(\n",
    "        \"theta\",\n",
    "        a=pm.floatX((1.0 / n_topics) * np.ones((minibatch_size, n_topics))),\n",
    "        shape=(minibatch_size, n_topics),\n",
    "        total_size=n_samples,\n",
    "    )\n",
    "    \n",
    "    beta = Dirichlet(\n",
    "        \"beta\",\n",
    "        a=pm.floatX((1.0 / n_topics) * np.ones((n_topics, n_words))),\n",
    "        shape=(n_topics, n_words),\n",
    "    )\n",
    "    \n",
    "    doc = pm.DensityDist(\"doc\", log_prob(beta, theta), observed=doc_t)\n",
    "    \n",
    "#     step = pm.HamiltonianMC()\n",
    "#     step = pm.Metropolis()\n",
    "#     trace = pm.sample(1000, step)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Top words in each topic basd on the posterior mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LDAEncoder:\n",
    "    \"\"\"Encode (term-frequency) document vectors to variational means and (log-transformed) stds.\"\"\"\n",
    "\n",
    "    def __init__(self, n_words, n_hidden, n_topics, p_corruption=0, random_seed=1):\n",
    "        rng = np.random.RandomState(random_seed)\n",
    "        self.n_words = n_words\n",
    "        self.n_hidden = n_hidden\n",
    "        self.n_topics = n_topics\n",
    "        self.w0 = shared(0.01 * rng.randn(n_words, n_hidden).ravel(), name=\"w0\")\n",
    "        self.b0 = shared(0.01 * rng.randn(n_hidden), name=\"b0\")\n",
    "        \n",
    "        self.w1 = shared(0.01 * rng.randn(n_hidden, n_hidden).ravel(), name=\"w1\")\n",
    "        self.b1 = shared(0.01 * rng.randn(n_hidden), name=\"b1\")\n",
    "        \n",
    "        self.w2 = shared(0.01 * rng.randn(n_hidden, 2 * (n_topics - 1)).ravel(), name=\"w2\")\n",
    "        self.b2 = shared(0.01 * rng.randn(2 * (n_topics - 1)), name=\"b2\")\n",
    "        self.rng = MRG_RandomStreams(seed=random_seed)\n",
    "\n",
    "    def encode(self, xs):\n",
    "\n",
    "        w0 = self.w0.reshape((self.n_words, self.n_hidden))\n",
    "        w1 = self.w1.reshape((self.n_hidden, self.n_hidden))\n",
    "        w2 = self.w2.reshape((self.n_hidden, 2 * (self.n_topics - 1)))\n",
    "\n",
    "        hs = tt.tanh(xs.dot(w0) + self.b0)\n",
    "        hs = tt.tanh(hs.dot(w1) + self.b1)\n",
    "        zs = hs.dot(w2) + self.b2\n",
    "        zs_mean = zs[:, : (self.n_topics - 1)]\n",
    "        zs_rho = zs[:, (self.n_topics - 1) :]\n",
    "        return {\"mu\": zs_mean, \"rho\": zs_rho}\n",
    "\n",
    "    def get_params(self):\n",
    "        return [self.w0, self.b0, self.w1, self.b1, self.w2, self.b2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[w0, b0, w1, b1, w2, b2]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = LDAEncoder(n_words=n_words, n_hidden=100, n_topics=n_topics, p_corruption=0.0)\n",
    "local_RVs = OrderedDict([(theta, encoder.encode(doc_t))])\n",
    "# local_RVs\n",
    "\n",
    "encoder_params = encoder.get_params()\n",
    "encoder_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s]/home/liutianc/miniconda3/lib/python3.7/site-packages/theano/tensor/subtensor.py:2197: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  rval = inputs[0].__getitem__(inputs[1:])\n",
      "Average Loss = 1.0475e+07: 100%|██████████| 1000/1000 [04:00<00:00,  4.15it/s]\n",
      "Finished [100%]: Average Loss = 1.0468e+07\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pymc3.variational.approximations.MeanField at 0x7f7ec35a0250>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "η = .1\n",
    "s = shared(η)\n",
    "\n",
    "\n",
    "def reduce_rate(a, h, i):\n",
    "    s.set_value(η / ((i / minibatch_size) + 1) ** 0.7)\n",
    "\n",
    "with model:\n",
    "    approx = pm.MeanField(local_rv=local_RVs)\n",
    "    approx.scale_cost_to_minibatch = False\n",
    "    inference = pm.KLqp(approx)\n",
    "    \n",
    "inference.fit(\n",
    "    1000,\n",
    "    callbacks=[reduce_rate, \n",
    "               pm.callbacks.CheckParametersConvergence(diff=\"absolute\")],\n",
    "    obj_optimizer=pm.adam(learning_rate=s),\n",
    "    more_obj_params=encoder_params,\n",
    "    total_grad_norm_constraint=200,\n",
    "    more_replacements={doc_t: doc_t_minibatch},\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(approx.hist[10:]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #0: like ,even ,bad ,good ,would ,really ,time ,see ,much ,get\n",
      "Topic #1: good ,ever ,better ,even ,acting ,make ,people ,really ,boring ,also\n",
      "Topic #2: bad ,good ,like ,could ,really ,even ,also ,actually ,fact ,made\n",
      "Topic #3: good ,even ,like ,much ,better ,get ,bad ,characters ,actually ,audio\n",
      "Topic #4: like ,good ,acting ,get ,much ,instead ,better ,bad ,make ,every\n",
      "Topic #5: even ,ever ,bad ,also ,back ,character ,better ,certain ,cable ,good\n",
      "Topic #6: bad ,find ,another ,anyone ,finally ,could ,actors ,able ,character ,back\n",
      "Topic #7: even ,also ,bad ,could ,like ,good ,man ,believed ,dance ,ancient\n",
      "Topic #8: even ,amateur ,back ,desperately ,bloody ,cousin ,etc ,attempts ,eat ,comedy\n",
      "Topic #9: bad ,body ,course ,another ,actually ,away ,add ,common ,almost ,always\n",
      "Topic #10: like ,acting ,best ,circumstances ,even ,family ,agreed ,cat ,bad ,angles\n",
      "Topic #11: actually ,despite ,actors ,basically ,better ,get ,could ,end ,according ,angeles\n",
      "Topic #12: get ,bad ,could ,even ,always ,attack ,basic ,age ,boy ,already\n",
      "Topic #13: beethoven ,better ,bad ,author ,ann ,according ,characters ,boring ,andy ,bit\n",
      "Topic #14: characters ,bad ,see ,budget ,could ,back ,blood ,based ,car ,even\n",
      "Topic #15: every ,excuse ,brilliant ,africa ,advise ,anywhere ,cutting ,avoid ,actors ,attitude\n",
      "Topic #16: airport ,far ,actresses ,acting ,directly ,becomes ,cuts ,cry ,cops ,avoid\n",
      "Topic #17: like ,good ,age ,apparently ,criminals ,edge ,actor ,check ,characters ,almost\n",
      "Topic #18: movies ,also ,could ,arthur ,abilities ,blockbuster ,brief ,deep ,advice ,anything\n",
      "Topic #19: like ,also ,away ,acting ,back ,actually ,compare ,ago ,arm ,air\n"
     ]
    }
   ],
   "source": [
    "def print_top_words(beta, feature_names, n_top_words=10):\n",
    "    for i in range(len(beta)):\n",
    "        print(\n",
    "            (\"Topic #%d: \" % i)\n",
    "            + \" ,\".join([feature_names[j] for j in beta[i].argsort()[: -n_top_words - 1 : -1]])\n",
    "        )\n",
    "\n",
    "\n",
    "doc_t.set_value(docs_tr.toarray())\n",
    "samples = pm.sample_approx(approx, draws=100)\n",
    "beta_pymc3 = samples[\"beta\"].mean(axis=0)\n",
    "\n",
    "print_top_words(beta_pymc3, feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_pp(ws, thetas, beta, wix):\n",
    "    return ws * np.log(thetas.dot(beta[:, wix]))\n",
    "\n",
    "\n",
    "def eval_lda(transform, beta, docs_te, wixs):\n",
    "    \"\"\"Evaluate LDA model by log predictive probability.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    transform: Python function\n",
    "        Transform document vectors to posterior mean of topic proportions.\n",
    "    wixs: iterable of int\n",
    "        Word indices to be held-out.\n",
    "    \"\"\"\n",
    "    lpss = []\n",
    "    docs_ = deepcopy(docs_te)\n",
    "    thetass = []\n",
    "    wss = []\n",
    "    total_words = 0\n",
    "    for wix in wixs:\n",
    "        ws = docs_te[:, wix].ravel()\n",
    "        if 0 < ws.sum():\n",
    "            # Hold-out\n",
    "            docs_[:, wix] = 0\n",
    "\n",
    "            # Topic distributions\n",
    "            thetas = transform(docs_)\n",
    "\n",
    "            print(thetas.shape)\n",
    "            raise ValueError()\n",
    "            # Predictive log probability\n",
    "            lpss.append(calc_pp(ws, thetas, beta, wix))\n",
    "\n",
    "            docs_[:, wix] = ws\n",
    "            thetass.append(thetas)\n",
    "            wss.append(ws)\n",
    "            total_words += ws.sum()\n",
    "        else:\n",
    "            thetass.append(None)\n",
    "            wss.append(None)\n",
    "\n",
    "    # Log-probability\n",
    "    lp = np.sum(np.hstack(lpss)) / total_words\n",
    "\n",
    "    return {\"lp\": lp, \"thetass\": thetass, \"beta\": beta, \"wss\": wss}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/liutianc/miniconda3/lib/python3.7/site-packages/theano/scan_module/scan_perform_ext.py:76: UserWarning: The file scan_perform.c is not available. This donot happen normally. You are probably in a strangesetup. This mean Theano can not use the cython code for scan. If youwant to remove this warning, use the Theano flag'cxx=' (set to an empty string) to disable all ccode generation.\n",
      "  \"The file scan_perform.c is not available. This do\"\n",
      "/home/liutianc/miniconda3/lib/python3.7/site-packages/theano/scan_module/scan_perform_ext.py:76: UserWarning: The file scan_perform.c is not available. This donot happen normally. You are probably in a strangesetup. This mean Theano can not use the cython code for scan. If youwant to remove this warning, use the Theano flag'cxx=' (set to an empty string) to disable all ccode generation.\n",
      "  \"The file scan_perform.c is not available. This do\"\n"
     ]
    }
   ],
   "source": [
    "inp = tt.matrix(dtype=\"int64\")\n",
    "sample_vi_theta = theano.function(\n",
    "    [inp], approx.sample_node(approx.model.theta, 100, more_replacements={doc_t: inp}).mean(0), \n",
    ")\n",
    "\n",
    "sample_vi_n = theano.function(\n",
    "    [inp], approx.sample_node(approx.model.beta, 100, more_replacements={doc_t: inp}).mean(0), \n",
    ")\n",
    "# \n",
    "\n",
    "def transform_pymc3(docs):\n",
    "    return sample_vi_theta(docs), sample_vi_n(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictive log prob (pm3) = -7.13164636963113\n"
     ]
    }
   ],
   "source": [
    "result_pymc3 = eval_lda(\\\n",
    "      transform_pymc3, beta_pymc3, docs_tr.toarray(), np.arange(100)\\\n",
    "  )\n",
    "\n",
    "print(\"Predictive log prob (pm3) = {}\".format(result_pymc3[\"lp\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
